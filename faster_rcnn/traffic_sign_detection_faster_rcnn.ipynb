{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_train = np.genfromtxt('train/gt_train.txt', delimiter =';', dtype = None, encoding = None)\n",
    "\n",
    "#creating a dictionary with image names as key and annotations as value\n",
    "dic_train ={}\n",
    "for i in range (0, len(txt_train)):\n",
    "    \n",
    "    #image name is first element of annotation file\n",
    "    img_name = txt_train[i][0]\n",
    "    #4 coordinates\n",
    "    target = [txt_train[i][1], txt_train[i][2], txt_train[i][3], txt_train[i][4], txt_train[i][5]]\n",
    "    #last element is the class number\n",
    "    cls = txt_train[i][-1]\n",
    "    #if multiple objects, store coordinates and classes as list of lists\n",
    "    if(img_name in dic_train):\n",
    "        dic_train[img_name].append(target)\n",
    "    else:\n",
    "        dic_train[img_name] = [target]\n",
    "\n",
    "print(\"Number of Images: \" + str(len(dic_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_valid = np.genfromtxt('valid/gt_valid.txt', delimiter =';', dtype = None, encoding = None)\n",
    "\n",
    "#creating a dictionary with image names as key and annotations as value\n",
    "dic_valid ={}\n",
    "for i in range (0, len(txt_valid)):\n",
    "\n",
    "    #image name is first element of annotation file\n",
    "    img_name = txt_valid[i][0]\n",
    "    #4 coordinates\n",
    "    target = [txt_valid[i][1], txt_valid[i][2], txt_valid[i][3], txt_valid[i][4], txt_valid[i][5]]\n",
    "    #last element is the class number\n",
    "    cls = txt_valid[i][-1]\n",
    "    #if multiple objects, store coordinates and classes as list of lists\n",
    "    if(img_name in dic_valid):\n",
    "        dic_valid[img_name].append(target)\n",
    "    else:\n",
    "        dic_valid[img_name] = [target]\n",
    "\n",
    "print(\"Number of Images: \" + str(len(dic_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, _dic, transforms = None):\n",
    "\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.dic = _dic\n",
    " \n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #convert the numpy array to PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "        #get objects in the image\n",
    "        objects = self.dic[self.imgs[idx]]\n",
    "        #get bounding box coordinates for each object in image\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in objects:\n",
    "            name = obj[-1]\n",
    "            labels.append(np.int(name))\n",
    "            #get bounding box coordinates\n",
    "            xmin = np.float(obj[0])\n",
    "            ymin = np.float(obj[1])\n",
    "            xmax = np.float(obj[2])\n",
    "            ymax = np.float(obj[3])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype = torch.int64)        \n",
    " \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        #suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(objects),), dtype = torch.int64)\n",
    " \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    " \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    " \n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilss\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    " \n",
    "def get_transform(train):\n",
    "\n",
    "    transforms = []\n",
    "    #converts a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utilss\n",
    "import torch.nn as nn\n",
    "os.environ['TORCH_HOME'] = ''\n",
    "\n",
    "root_train = r'train'\n",
    "root_valid = r'valid'\n",
    "\n",
    "#train on the GPU if available else CPU.\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "#44 classes = 43 + background\n",
    "num_classes = 44\n",
    "#send the data to the myDataset class (Apply transformations, Get bbox, labels, objects)\n",
    "dataset_train = myDataset(root_train, _dic = dic_train, transforms = get_transform(train = True))\n",
    "dataset_valid = myDataset(root_valid, _dic = dic_valid, transforms = get_transform(train = False))\n",
    "\n",
    "#define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset_train, batch_size = 2, shuffle = True, collate_fn = utilss.collate_fn)\n",
    "data_loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size = 2, shuffle = False, collate_fn = utilss.collate_fn)\n",
    "\n",
    "# Define model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = False, progress = True, num_classes = num_classes, pretrained_backbone = True)\n",
    "\n",
    "#move the model to device\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_all(epoch, losses, loss_box_reg, loss_rpn_box_reg, loss_classifier, loss_objectness, stat0, stat1, stat2, stat3,\n",
    "        stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11, optimizer):\n",
    "\n",
    "    with open(f'varsTest{epoch}.pickle', 'wb') as f:\n",
    "        pickle.dump([losses, loss_box_reg, loss_rpn_box_reg, loss_classifier, loss_objectness, stat0, stat1, stat2, stat3,\n",
    "        stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11], f)\n",
    "\n",
    "    torch.save(model, f'trainTest{epoch}.pkl')\n",
    "\n",
    "    torch.save(model.state_dict(), f'trainTest{epoch}.pth')\n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        \"model_state_dict\" : model.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    }, f'ckptTest{epoch}.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utilss\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "#constructing the optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "# SGD\n",
    "optimizer = torch.optim.SGD(params, lr = 0.0005, momentum = 0.9, weight_decay = 0.0005)\n",
    "\n",
    "#learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 1, T_mult = 2)\n",
    "\n",
    "num_epochs = 1000\n",
    "losses = []\n",
    "loss_box_reg = []\n",
    "loss_rpn_box_reg = []\n",
    "loss_classifier = []\n",
    "loss_objectness = []\n",
    "\n",
    "stat0 = []\n",
    "stat1 = []\n",
    "stat2 = []\n",
    "stat3 = []\n",
    "stat4 = []\n",
    "stat5 = []\n",
    "stat6 = []\n",
    "stat7 = []\n",
    "stat8 = []\n",
    "stat9 = []\n",
    "stat10 = []\n",
    "stat11 = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    metrics = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq = 1000)\n",
    "    losses.append(float(str(metrics.meters['loss']).split(\" \")[0]))\n",
    "    loss_box_reg.append(float(str(metrics.meters['loss_box_reg']).split(\" \")[0]))\n",
    "    loss_rpn_box_reg.append(float(str(metrics.meters['loss_rpn_box_reg']).split(\" \")[0]))\n",
    "    loss_classifier.append(float(str(metrics.meters['loss_classifier']).split(\" \")[0]))\n",
    "    loss_objectness.append(float(str(metrics.meters['loss_objectness']).split(\" \")[0]))\n",
    "\n",
    "    #update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    #evaluate on the test dataset\n",
    "    _, metric_logger = evaluate(model, data_loader_valid, device=device)\n",
    "\n",
    "    stat = _.coco_eval['bbox'].stats\n",
    "    \n",
    "    #append all stats\n",
    "    stat0.append(stat[0])\n",
    "    stat1.append(stat[1])\n",
    "    stat2.append(stat[2])\n",
    "    stat3.append(stat[3])\n",
    "    stat4.append(stat[4])\n",
    "    stat5.append(stat[5])\n",
    "    stat6.append(stat[6])\n",
    "    stat7.append(stat[7])\n",
    "    stat8.append(stat[8])\n",
    "    stat9.append(stat[9])\n",
    "    stat10.append(stat[10])\n",
    "    stat11.append(stat[11])\n",
    "    \n",
    "    #save model after each 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        save_all(epoch, losses, loss_box_reg, loss_rpn_box_reg, loss_classifier, loss_objectness, stat0, stat1, stat2, stat3,\n",
    "        stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11, optimizer)\n",
    "    \n",
    "    print('')\n",
    "    print('==================================================')\n",
    "    print('')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = 9,2\n",
    "fig, ax = plt.subplots(nrows=r, ncols=c)\n",
    "fig.set_figheight(40)\n",
    "fig.set_figwidth(10)\n",
    "fig.subplots_adjust(left=14,right=15, top=6, bottom=5, hspace=1, wspace=1)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(r, c, 1)\n",
    "ax1.set_title(\"Losses\")\n",
    "ax2 = plt.subplot(r, c, 2)\n",
    "ax2.set_title(\"Loss Box Reg\")\n",
    "ax3 = plt.subplot(r, c, 3)\n",
    "ax3.set_title(\"Loss RPN Box Reg\")\n",
    "ax4 = plt.subplot(r, c, 4)\n",
    "ax4.set_title(\"Loss Classifier\")\n",
    "ax5 = plt.subplot(r, c, 5)\n",
    "ax5.set_title(\"Loss Objectness\")\n",
    "ax6 = plt.subplot(r, c, 6)\n",
    "ax6.set_title(\"(AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100\")\n",
    "ax7 = plt.subplot(r, c, 7)\n",
    "ax7.set_title(\"(AP) @[ IoU=0.50      | area=   all | maxDets=100\")\n",
    "ax8 = plt.subplot(r, c, 8)\n",
    "ax8.set_title(\"(AP) @[ IoU=0.75      | area=   all | maxDets=100\")\n",
    "ax9 = plt.subplot(r, c, 9)\n",
    "ax9.set_title(\"(AP) @[ IoU=0.50:0.95 | area= small | maxDets=100\")\n",
    "ax10 = plt.subplot(r, c, 10)\n",
    "ax10.set_title(\"(AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100\")\n",
    "ax11 = plt.subplot(r, c, 11)\n",
    "ax11.set_title(\"(AP) @[ IoU=0.50:0.95 | area= large | maxDets=100\")\n",
    "ax12 = plt.subplot(r, c, 12)\n",
    "ax12.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1\")\n",
    "ax13 = plt.subplot(r, c, 13)\n",
    "ax13.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10\")\n",
    "ax14 = plt.subplot(r, c, 14)\n",
    "ax14.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100\")\n",
    "ax15 = plt.subplot(r, c, 15)\n",
    "ax15.set_title(\"(AR) @[ IoU=0.50:0.95 | area= small | maxDets=100\")\n",
    "ax16 = plt.subplot(r, c, 16)\n",
    "ax16.set_title(\"(AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100\")\n",
    "ax17 = plt.subplot(r, c, 17)\n",
    "ax17.set_title(\"(AR) @[ IoU=0.50:0.95 | area= large | maxDets=100\")\n",
    "\n",
    "ax1.plot(losses, 'b')\n",
    "ax2.plot(loss_box_reg, 'b')\n",
    "ax3.plot(loss_rpn_box_reg, 'b')\n",
    "ax4.plot(loss_classifier, 'b')\n",
    "ax5.plot(loss_objectness, 'b')\n",
    "ax1.plot(losses, 'b')\n",
    "ax2.plot(loss_box_reg, 'b')\n",
    "ax3.plot(loss_rpn_box_reg, 'b')\n",
    "ax4.plot(loss_classifier, 'b')\n",
    "ax5.plot(loss_objectness, 'b')\n",
    "ax6.plot(stat0, 'b')\n",
    "ax7.plot(stat1, 'b')\n",
    "ax8.plot(stat2, 'b')\n",
    "ax9.plot(stat3, 'b')\n",
    "ax10.plot(stat4, 'b')\n",
    "ax11.plot(stat5, 'b')\n",
    "ax12.plot(stat6, 'b')\n",
    "ax13.plot(stat7, 'b')\n",
    "ax14.plot(stat8, 'b')\n",
    "ax15.plot(stat9, 'b')\n",
    "ax16.plot(stat10, 'b')\n",
    "ax17.plot(stat11, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('vars5.pickle', 'rb') as f:\n",
    "    x = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
