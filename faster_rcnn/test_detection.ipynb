{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import utilss\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "model = torch.load(r'train1000.pkl')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = glob(\"test/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showbbox(model, img, base_name):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img.to(device)])\n",
    "    b = prediction[0]['boxes']\n",
    "    s = prediction[0]['scores']\n",
    "    \n",
    "    #apply Non-maximum suppression:\n",
    "    keep = torchvision.ops.nms(b,s,0.1)\n",
    "        \n",
    "    img = img.permute(1,2,0)  # C,H,W_H,W,C, for drawing\n",
    "    img = (img * 255).byte().data.cpu()  # * 255, float to 0-255\n",
    "    img = np.array(img)  # tensor â†’ ndarray\n",
    "    #convert np array img to right format.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    classes = { 1: \"Ahead_only\",\n",
    "                2: \"Beware_of_ice_snow\",\n",
    "                3: \"Bicycles_crossing\",\n",
    "                4: \"Bumpy_road\",\n",
    "                5: \"Children_crossing\",\n",
    "                6: \"Dangerous_curve_to_the_left\",\n",
    "                7: \"Dangerous_curve_to_the_right\",\n",
    "                8: \"Double_curve\",\n",
    "                9: \"End_of_all_speed_and_passing_limits\",\n",
    "                10: \"End_of_no_passing\",\n",
    "                11: \"End_of_no_passing_by_vehicles_over_3_5_metric_tons\",\n",
    "                12: \"End_of_speed_limit_80_km_h\",\n",
    "                13: \"General_caution\",\n",
    "                14: \"Go_straight_or_left\",\n",
    "                15: \"Go_straight_or_right\",\n",
    "                16: \"Keep_left\",\n",
    "                17: \"Keep_right\",\n",
    "                18: \"No_entry\",\n",
    "                19: \"No_passing\",\n",
    "                20: \"No_passing_for_vehicles_over_3_5_metric_tons\",\n",
    "                21: \"No_vehicles\",\n",
    "                22: \"Pedestrians\",\n",
    "                23: \"Priority_road\",\n",
    "                24: \"Right_of_way_at_the_next_intersection\",\n",
    "                25: \"Road_narrows_on_the_right\",\n",
    "                26: \"Road_work\",\n",
    "                27: \"Roundabout_mandatory\",\n",
    "                28: \"Slippery_road\",\n",
    "                29: \"Speed_limit_100_km_h\",\n",
    "                30: \"Speed_limit_120_km_h\",\n",
    "                31: \"Speed_limit_20_km_h\",\n",
    "                32: \"Speed_limit_30_km_h\",\n",
    "                33: \"Speed_limit_50_km_h\",\n",
    "                34: \"Speed_limit_60_km_h\",\n",
    "                35: \"Speed_limit_70_km_h\",\n",
    "                36: \"Speed_limit_80_km_h\",\n",
    "                37: \"Stop\",\n",
    "                38: \"Traffic_signals\",\n",
    "                39: \"Turn_left_ahead\",\n",
    "                40: \"Turn_right_ahead\",\n",
    "                41: \"Vehicles_over_3_5_metric_tons_prohibited\",\n",
    "                42: \"Wild_animals_crossing\",\n",
    "                43: \"Yield\"}\n",
    "\n",
    "    for k in range(len(keep)):\n",
    "\n",
    "        xmin = round(prediction[0]['boxes'][k][0].item())\n",
    "        ymin = round(prediction[0]['boxes'][k][1].item())\n",
    "        xmax = round(prediction[0]['boxes'][k][2].item())\n",
    "        ymax = round(prediction[0]['boxes'][k][3].item())\n",
    "        \n",
    "        label = prediction[0]['labels'][k].item()\n",
    "        print(label)\n",
    "        colors = np.random.uniform(0, 255, size = (43, 3))\n",
    "        if label in classes:\n",
    "\n",
    "            pt1 = (xmin, ymin)\n",
    "            pt2 = (xmax, ymax)\n",
    "            score = prediction[0]['scores'][k].item()\n",
    "            color = list(colors[label - 1])\n",
    "            if score >= 0.6:\n",
    "                cv2.rectangle(img, pt1, pt2, color, thickness = 2)\n",
    "                cv2.putText(img, classes[label] + \"-\" + str(round(score, 2)), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color,\n",
    "                        thickness = 2)\n",
    "\n",
    "    cv2.imwrite(f'results/{base_name}.png', img)\n",
    "\n",
    "print(\"Function Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in test_images:\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    #convert from BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #convert the numpy array to PIL Image\n",
    "    img = Image.fromarray(img)\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    showbbox(model, img_tensor, base_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
